{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anonymous-aviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--lr LR] [--batch-size BATCH_SIZE]\n",
      "                             [--epochs EPOCHS] [--train-path TRAIN_PATH]\n",
      "                             [--save-path SAVE_PATH] [--with-ray WITH_RAY]\n",
      "                             [--num-workers NUM_WORKERS] [--use-gpu USE_GPU]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-ff93039f-0248-4c7d-b507-6375a61f06b8.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from model import resnet34\n",
    "import time\n",
    "from typing import Dict\n",
    "#添加ray分布式训练\n",
    "import ray\n",
    "import ray.train as train\n",
    "from ray.train.trainer import Trainer\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data import DistributedSampler\n",
    "from ray.train.callbacks import JsonLoggerCallback\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def data_load(args):\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \"val\": transforms.Compose([transforms.Resize(256),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "    image_path = args.train_path\n",
    "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                         transform=data_transform[\"train\"])\n",
    "    train_num = len(train_dataset)\n",
    "    car_list = train_dataset.class_to_idx\n",
    "    cla_dict = dict((val, key) for key, val in car_list.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(cla_dict, indent=4)\n",
    "    with open('class_index.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    batch_size = args.batch_size  # batch_size设定大小\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                                        transform=data_transform[\"val\"])\n",
    "    val_num=len(validate_dataset)\n",
    "    if args.with_ray:\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,sampler=DistributedSampler(train_dataset))\n",
    "        validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                 sampler=DistributedSampler(validate_dataset))\n",
    "    else:\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True,num_workers=nw)\n",
    "        validate_loader = torch.utils.data.DataLoader(validate_dataset,batch_size=batch_size, shuffle=False,num_workers=nw)\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "\n",
    "    return train_loader,validate_loader\n",
    "\n",
    "\n",
    "def train_epoch(net,train_loader,optimizer,device,loss_function,epoch,epochs):\n",
    "    net.train()\n",
    "    tr_loss = 0.0\n",
    "    true = 0\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(images.to(device))\n",
    "        loss = loss_function(logits, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        tr_loss += loss.item()\n",
    "        true += (logits.argmax(1) == labels.to(device)).type(torch.float).sum().item()\n",
    "        acc=100*(logits.argmax(1) == labels.to(device)).type(torch.float).sum().item()/len(labels)\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f} acc:{:.3f}%\".format(epoch + 1,\n",
    "                                                                 epochs,\n",
    "                                                                 loss,acc)\n",
    "    tr_acc = (true / len(train_loader.dataset)) * 100.\n",
    "    return tr_loss, tr_acc, net\n",
    "\n",
    "def valid_epoch(net,validate_loader,device,loss_function,epoch,epochs,best_acc,save_path):\n",
    "    # validate\n",
    "    net.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    va_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = net(val_images.to(device))\n",
    "            loss = loss_function(outputs, val_labels.to(device))\n",
    "            va_loss+=loss.item()\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "            val_acc = 100 * (outputs.argmax(1) == val_labels.to(device)).type(torch.float).sum().item() / len(val_labels)\n",
    "\n",
    "            val_bar.desc = \"valid epoch[{}/{}] loss:{:.3f} acc:{:.3f}%\".format(epoch + 1,\n",
    "                                                       epochs,loss,val_acc)\n",
    "    val_accurate = acc / len(validate_loader.dataset)\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "    return va_loss,val_accurate,best_acc\n",
    "\n",
    "\n",
    "def train_validate_network_with_ray(config: Dict):\n",
    "    args = config['args']\n",
    "    tr_loader,va_loader = data_load(args)\n",
    "\n",
    "    net = resnet34()\n",
    "    # load pretrain weights\n",
    "    model_weight_path = \"./resnet34-333f7ec4.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net.load_state_dict(torch.load(model_weight_path))\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "    device = torch.device(f\"cuda:{train.local_rank()}\" if args.use_gpu else \"cpu\")\n",
    "\n",
    "    # change fc layer structure\n",
    "    print(train.local_rank())\n",
    "    in_channel = net.fc.in_features\n",
    "    net.fc = nn.Linear(in_channel, 1777)\n",
    "    net.to(device)\n",
    "    model = DistributedDataParallel(net, device_ids=[train.local_rank()])\n",
    "\n",
    "    # define loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    epochs = args.epochs  # 设定次数\n",
    "    best_acc = 0.0\n",
    "    save_path = args.save_path  # 保存模型的名字\n",
    "    tr_loss, tr_acc, va_loss, va_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        tr_loss1, tr_acc1, model = train_epoch(model,tr_loader,optimizer,device,loss_function,epoch,epochs)\n",
    "        va_loss1, va_acc1,best_acc = valid_epoch(model,va_loader,device,loss_function,epoch,epochs,best_acc,save_path)\n",
    "        train.report(loss=va_loss1)\n",
    "        tr_loss.append(tr_loss1)\n",
    "        tr_acc.append(tr_acc1)\n",
    "        va_loss.append(va_loss1)\n",
    "        va_acc.append(va_acc1)\n",
    "\n",
    "    return tr_loss, tr_acc, va_loss, va_acc\n",
    "\n",
    "\n",
    "def train_validate_network(args):\n",
    "\n",
    "    tr_loader,va_loader = data_load(args)\n",
    "\n",
    "    net = resnet34()\n",
    "    # load pretrain weights\n",
    "    model_weight_path = \"./resnet34-333f7ec4.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net.load_state_dict(torch.load(model_weight_path))\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if args.use_gpu else \"cpu\")\n",
    "\n",
    "    # change fc layer structure\n",
    "    in_channel = net.fc.in_features\n",
    "    net.fc = nn.Linear(in_channel, 1777)\n",
    "    net.to(device)\n",
    "    model = net\n",
    "    # define loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    epochs = args.epochs  # 设定次数\n",
    "    best_acc = 0.0\n",
    "    save_path = args.save_path  # 保存模型的名字\n",
    "    tr_loss, tr_acc, va_loss, va_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        tr_loss1, tr_acc1, model = train_epoch(model,tr_loader,optimizer,device,loss_function,epoch,epochs)\n",
    "        va_loss1, va_acc1,best_acc = valid_epoch(model,va_loader,device,loss_function,epoch,epochs,best_acc,save_path)\n",
    "        tr_loss.append(tr_loss1)\n",
    "        tr_acc.append(tr_acc1)\n",
    "        va_loss.append(va_loss1)\n",
    "        va_acc.append(va_acc1)\n",
    "\n",
    "    return tr_loss, tr_acc, va_loss, va_acc\n",
    "\n",
    "def plot_acc_loss(args, tr_loss, tr_acc, va_loss, va_acc):\n",
    "    if not args.with_ray:\n",
    "        plt.plot(tr_acc)\n",
    "        plt.plot(va_acc)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(['train', 'validation'])\n",
    "        plt.savefig('./acc.png')\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(tr_loss)\n",
    "        plt.plot(va_loss)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(['train', 'validation'])\n",
    "        plt.savefig('./loss.png')\n",
    "        plt.close()\n",
    "\n",
    "    if args.with_ray:\n",
    "        plt.plot(tr_acc)\n",
    "        plt.plot(va_acc)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(['train1', 'validation1', 'train2', 'validation2'])\n",
    "        plt.savefig('./acc_with_ray.png')\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(tr_loss)\n",
    "        plt.plot(va_loss)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(['train1', 'validation1', 'train2', 'validation2'])\n",
    "        plt.savefig('./loss_with_ray.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Resnet34 Transfer Learning Image Classification',formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='batch size')\n",
    "    parser.add_argument('--epochs', type=int, default=10, help='epochs')\n",
    "    parser.add_argument('--train-path', type=str, default='../../myData', help='dataset path')\n",
    "    parser.add_argument('--save-path', type=str, default='./resnet34.pth', help='model save path')\n",
    "    parser.add_argument('--with-ray', type=bool, default=True, help='with Ray')\n",
    "    parser.add_argument('--num-workers', type=int, default=2, help='number of workers')\n",
    "    parser.add_argument('--use-gpu', type=bool, default=True, help='choose divice for training')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    start = time.time()\n",
    "    if not args.with_ray:\n",
    "        tr_loss, tr_acc, va_loss, va_acc = train_validate_network(args)\n",
    "        end = time.time()\n",
    "        print(f\"Training and validation time: {end-start:>.2f}\")\n",
    "    elif args.with_ray:\n",
    "        if args.use_gpu:\n",
    "            ray.init(num_gpus=args.num_workers)\n",
    "        else:\n",
    "            ray.init(num_cpus=args.num_workers)\n",
    "        trainer = Trainer(backend=\"torch\", num_workers=args.num_workers, use_gpu=args.use_gpu)\n",
    "        trainer.start()\n",
    "        res = trainer.run(train_func=train_validate_network_with_ray, config={'args':args}, callbacks=[JsonLoggerCallback()])\n",
    "        trainer.shutdown()\n",
    "        end = time.time()\n",
    "        print(f\"Training and validation time: {end - start:.>2f}\")\n",
    "        tr_loss, tr_acc, va_loss, va_acc = [], [], [], []\n",
    "        for idx_w in range(args.num_workers):\n",
    "            tmp_res = res[idx_w]\n",
    "            tr_loss.append(tmp_res[0])\n",
    "            tr_acc.append(tmp_res[1])\n",
    "            va_loss.append(tmp_res[2])\n",
    "            va_acc.append(tmp_res[3])\n",
    "        tr_loss = np.average(tr_loss, 0)\n",
    "        tr_acc = np.average(tr_acc, 0)\n",
    "        va_loss = np.average(va_loss, 0)\n",
    "        va_acc = np.average(va_acc, 0)\n",
    "        plot_acc_loss(args, tr_loss, tr_acc, va_loss, va_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-contemporary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
